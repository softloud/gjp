---
title: "GJP data"
author: "Charles T. Gray"
date: "10/09/2019"
output: 
    html_document: 
        toc: true
        toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

```{r, message=FALSE}
# packages used in this analysis
library(tidyverse)
library(usethis)
library(here)

conflicted::conflict_prefer("filter", "dplyr")

```


## objective

> From Hannah:  "...the only thing we need at this point is a csv file with 4 columns:  participant_ID  question_ID  Prediction Outcome."

This is info I can work with, thank you! 

Anca helpfully provided the [data](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/BPCDH5). 


## import data

Downloaded all files files as a zip (see **analysis/raw-data**). Briliant, there's an informative readme associated with the data.

Okay, so, for me Download all did not work. Ugh. I *very* carefully downloaded all the files and copied them into **raw-data**, BUT there is one file that exceeds GitHub's 100MB file-size limit.   

Looking to munge out some variables for summary output. 

- `participant_ID` 
- `question_ID` - ifp_id
- `Prediction`  -  `pk_1_conf`
- `Outcome` - Political knowledge (dichotomous response ) `pk_1_cor`

only need binary questions

```{r eval=FALSE}
# not run bc file size too big

# grab the tabulated files
raw_meta_data <-
    tibble(file = list.files("analysis/data/raw_data/"),
           is_csv = str_detect(file, ".csv")) %>%
    filter(is_csv == TRUE) %>%
    mutate(file_path = paste0("analysis/data/raw_data/", file))

# read in data
raw_data <- raw_meta_data %>% pluck("file_path") %>%  map(read_csv)
names(raw_data) <- raw_meta_data %>% pluck("file")


```




```{r eval=FALSE}

# not run because file size too big
(meta_data <- raw_meta_data %>% 
    mutate(variables = map(raw_data, names),
           first_var = map_chr(variables, 2),
           pk_flag = map_lgl(variables, .f = function(x) {
               str_detect(x, "pk") %>% any()
           })))

write_rds(meta_data, path = "analysis/data/derived_data/meta_data.csv")

```


Let's take a look at the names and see if we can't find where the results of  `pk` are.

```{r}

# read in meta data 
meta_data <- read_rds(paste0(here::here(), "/analysis/data/derived_data/meta_data.rds"))

```

```{r}
# filter by tables that have pk as a column
meta_data %>% 
    filter(pk_flag) %>% 
    select(-pk_flag, -file_path, -is_csv) 

```


Okay, so, I think this is the data we're interested in is in the `all_individual differences.csv` file.

```{r eval=FALSE}
# raw data munging 



```

